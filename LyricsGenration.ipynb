{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "LyricsGenration.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CAedAKONulV",
        "outputId": "d788a342-c4d0-4063-c0d8-3b76b03e4daf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpJg393aNsR4"
      },
      "source": [
        "# Generate Lyrics from all Ed sheeran songs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg4IblSJNsSB"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKoIAio1Ohjj"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myt4hICROjDS"
      },
      "source": [
        "lyrics = pd.read_csv('/content/drive/MyDrive/LyricsGenration/lyrics-data.csv')\n",
        "lyrics = lyrics[lyrics['Idiom']=='ENGLISH']"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J58rZ_NjOucK"
      },
      "source": [
        "#Only keep popular artists, with genre Rock/Pop and popularity high enough\n",
        "artists = pd.read_csv('/content/drive/MyDrive/LyricsGenration/artists-data.csv')\n",
        "\n",
        "artists = artists[(artists['Genre'].isin(['Pop'])) & (artists['Popularity']>5)]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3roywNEjO1XS"
      },
      "source": [
        "data = lyrics.merge(artists[['Artist', 'Genre', 'Link']], left_on='ALink', right_on='Link', how='inner')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKfxuZmmO5bM"
      },
      "source": [
        "data = data.drop(columns=['ALink','SLink','Idiom','Link','Genre'])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgJ75PVtO9UK",
        "outputId": "581722da-b753-45c9-fb90-5dabe8ac1668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "#Keep last 20 words in a new column, then remove them from original column\n",
        "data['True_end_lyrics'] = data['Lyric'].str.split().str[-20:].apply(' '.join)\n",
        "data['Lyric'] = data['Lyric'].str.split().str[:-20].apply(' '.join)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SName</th>\n",
              "      <th>Lyric</th>\n",
              "      <th>Artist</th>\n",
              "      <th>True_end_lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Careless Whisper</td>\n",
              "      <td>I feel so unsure. As I take your hand and lead...</td>\n",
              "      <td>George Michael</td>\n",
              "      <td>now that you're gone. (now that you're gone) w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Freedom '90</td>\n",
              "      <td>I won't let you down. I will not give you up. ...</td>\n",
              "      <td>George Michael</td>\n",
              "      <td>what you want from me. Just the way it's got t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>One More Try</td>\n",
              "      <td>I've had enough of danger. And people on the s...</td>\n",
              "      <td>George Michael</td>\n",
              "      <td>joy. For an uptown boy. Who just isn't willing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Father Figure</td>\n",
              "      <td>That's all I wanted. Something special, someth...</td>\n",
              "      <td>George Michael</td>\n",
              "      <td>your preacher. I will be your daddy. I will be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Heal The Pain</td>\n",
              "      <td>Let me tell you a secret. Put it in your heart...</td>\n",
              "      <td>George Michael</td>\n",
              "      <td>your heart now. I'll be good to you. I can mak...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              SName  ...                                    True_end_lyrics\n",
              "0  Careless Whisper  ...  now that you're gone. (now that you're gone) w...\n",
              "1       Freedom '90  ...  what you want from me. Just the way it's got t...\n",
              "2      One More Try  ...  joy. For an uptown boy. Who just isn't willing...\n",
              "3     Father Figure  ...  your preacher. I will be your daddy. I will be...\n",
              "4     Heal The Pain  ...  your heart now. I'll be good to you. I can mak...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXRF6taaNsSD"
      },
      "source": [
        "data = data[(data['Artist']=='George Michael')]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zkhCZDv4NsSE",
        "outputId": "687cb637-038a-43b1-d217-186322496ced"
      },
      "source": [
        "l = list(data['True_end_lyrics'])\n",
        "l[0]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"now that you're gone. (now that you're gone) what I did so wrong. That you had to leave me alone\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9a024duJNsSE",
        "outputId": "74e39380-9145-4475-eb34-c8d878858e4f"
      },
      "source": [
        "import string\n",
        "def clean_text(txt):\n",
        "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
        "    txt = txt.replace(\"\\n\",\"\")\n",
        "    return txt \n",
        "\n",
        "corpus = [clean_text(x) for x in l]\n",
        "corpus[0]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'now that youre gone now that youre gone what i did so wrong that you had to leave me alone'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM_kEE4VNsSF",
        "outputId": "c507bceb-7c64-4a2d-b577-099b1b2ae8bb"
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "-PSy0BpwNsSF"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "def get_sequence_of_tokens(corpus):\n",
        "    ## tokenization\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "    \n",
        "    ## convert data to sequence of tokens \n",
        "    input_sequences = []\n",
        "    for line in corpus:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram_sequence = token_list[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "    return input_sequences, total_words\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCxd5uC9NsSG",
        "outputId": "829f68b2-8d88-4fb6-db9f-d55737552118"
      },
      "source": [
        "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
        "inp_sequences[:10]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[23, 8],\n",
              " [23, 8, 45],\n",
              " [23, 8, 45, 120],\n",
              " [23, 8, 45, 120, 23],\n",
              " [23, 8, 45, 120, 23, 8],\n",
              " [23, 8, 45, 120, 23, 8, 45],\n",
              " [23, 8, 45, 120, 23, 8, 45, 120],\n",
              " [23, 8, 45, 120, 23, 8, 45, 120, 46],\n",
              " [23, 8, 45, 120, 23, 8, 45, 120, 46, 2],\n",
              " [23, 8, 45, 120, 23, 8, 45, 120, 46, 2, 229]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "1ZO4tQomNsSG"
      },
      "source": [
        "def generate_padded_sequences(input_sequences):\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "    \n",
        "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    label = ku.to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, max_sequence_len\n",
        "\n",
        "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "9a96xh6zNsSH"
      },
      "source": [
        "def create_model(max_sequence_len, total_words):\n",
        "    input_len = max_sequence_len - 1\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Add Input Embedding Layer\n",
        "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
        "    \n",
        "    # Add Hidden Layer 1 - LSTM Layer\n",
        "    model.add(LSTM(100))\n",
        "    \n",
        "    # Add Output Layer\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = create_model(max_sequence_len, total_words)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TZFn6MqNsSH",
        "outputId": "8026a8ec-8368-4d56-9e44-5e4b1cb14c2b"
      },
      "source": [
        "model.fit(predictors, label, epochs=100, verbose=2)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "178/178 - 3s - loss: 0.4172\n",
            "Epoch 2/100\n",
            "178/178 - 3s - loss: 0.4199\n",
            "Epoch 3/100\n",
            "178/178 - 3s - loss: 0.4024\n",
            "Epoch 4/100\n",
            "178/178 - 3s - loss: 0.3594\n",
            "Epoch 5/100\n",
            "178/178 - 3s - loss: 0.3357\n",
            "Epoch 6/100\n",
            "178/178 - 3s - loss: 0.3167\n",
            "Epoch 7/100\n",
            "178/178 - 3s - loss: 0.2989\n",
            "Epoch 8/100\n",
            "178/178 - 3s - loss: 0.2849\n",
            "Epoch 9/100\n",
            "178/178 - 3s - loss: 0.2688\n",
            "Epoch 10/100\n",
            "178/178 - 3s - loss: 0.2573\n",
            "Epoch 11/100\n",
            "178/178 - 3s - loss: 0.2547\n",
            "Epoch 12/100\n",
            "178/178 - 3s - loss: 0.2389\n",
            "Epoch 13/100\n",
            "178/178 - 3s - loss: 0.2284\n",
            "Epoch 14/100\n",
            "178/178 - 3s - loss: 0.2198\n",
            "Epoch 15/100\n",
            "178/178 - 3s - loss: 0.1965\n",
            "Epoch 16/100\n",
            "178/178 - 3s - loss: 0.1860\n",
            "Epoch 17/100\n",
            "178/178 - 3s - loss: 0.1761\n",
            "Epoch 18/100\n",
            "178/178 - 3s - loss: 0.1925\n",
            "Epoch 19/100\n",
            "178/178 - 3s - loss: 0.1622\n",
            "Epoch 20/100\n",
            "178/178 - 3s - loss: 0.1506\n",
            "Epoch 21/100\n",
            "178/178 - 3s - loss: 0.1429\n",
            "Epoch 22/100\n",
            "178/178 - 3s - loss: 0.1397\n",
            "Epoch 23/100\n",
            "178/178 - 3s - loss: 0.1297\n",
            "Epoch 24/100\n",
            "178/178 - 3s - loss: 0.1235\n",
            "Epoch 25/100\n",
            "178/178 - 3s - loss: 0.1201\n",
            "Epoch 26/100\n",
            "178/178 - 3s - loss: 0.1103\n",
            "Epoch 27/100\n",
            "178/178 - 3s - loss: 0.1055\n",
            "Epoch 28/100\n",
            "178/178 - 3s - loss: 0.0989\n",
            "Epoch 29/100\n",
            "178/178 - 3s - loss: 0.0951\n",
            "Epoch 30/100\n",
            "178/178 - 3s - loss: 0.0911\n",
            "Epoch 31/100\n",
            "178/178 - 3s - loss: 0.0855\n",
            "Epoch 32/100\n",
            "178/178 - 3s - loss: 0.0809\n",
            "Epoch 33/100\n",
            "178/178 - 3s - loss: 0.1514\n",
            "Epoch 34/100\n",
            "178/178 - 3s - loss: 0.2949\n",
            "Epoch 35/100\n",
            "178/178 - 3s - loss: 0.1311\n",
            "Epoch 36/100\n",
            "178/178 - 3s - loss: 0.0939\n",
            "Epoch 37/100\n",
            "178/178 - 3s - loss: 0.0798\n",
            "Epoch 38/100\n",
            "178/178 - 3s - loss: 0.0758\n",
            "Epoch 39/100\n",
            "178/178 - 3s - loss: 0.0717\n",
            "Epoch 40/100\n",
            "178/178 - 3s - loss: 0.0673\n",
            "Epoch 41/100\n",
            "178/178 - 3s - loss: 0.0648\n",
            "Epoch 42/100\n",
            "178/178 - 3s - loss: 0.0626\n",
            "Epoch 43/100\n",
            "178/178 - 3s - loss: 0.0599\n",
            "Epoch 44/100\n",
            "178/178 - 3s - loss: 0.0595\n",
            "Epoch 45/100\n",
            "178/178 - 3s - loss: 0.0571\n",
            "Epoch 46/100\n",
            "178/178 - 3s - loss: 0.0563\n",
            "Epoch 47/100\n",
            "178/178 - 3s - loss: 0.0539\n",
            "Epoch 48/100\n",
            "178/178 - 3s - loss: 0.0521\n",
            "Epoch 49/100\n",
            "178/178 - 3s - loss: 0.0498\n",
            "Epoch 50/100\n",
            "178/178 - 3s - loss: 0.0495\n",
            "Epoch 51/100\n",
            "178/178 - 3s - loss: 0.0467\n",
            "Epoch 52/100\n",
            "178/178 - 3s - loss: 0.0452\n",
            "Epoch 53/100\n",
            "178/178 - 3s - loss: 0.0446\n",
            "Epoch 54/100\n",
            "178/178 - 3s - loss: 0.0723\n",
            "Epoch 55/100\n",
            "178/178 - 3s - loss: 0.1658\n",
            "Epoch 56/100\n",
            "178/178 - 3s - loss: 0.0720\n",
            "Epoch 57/100\n",
            "178/178 - 3s - loss: 0.0474\n",
            "Epoch 58/100\n",
            "178/178 - 3s - loss: 0.0439\n",
            "Epoch 59/100\n",
            "178/178 - 3s - loss: 0.0423\n",
            "Epoch 60/100\n",
            "178/178 - 3s - loss: 0.0418\n",
            "Epoch 61/100\n",
            "178/178 - 3s - loss: 0.0402\n",
            "Epoch 62/100\n",
            "178/178 - 3s - loss: 0.0387\n",
            "Epoch 63/100\n",
            "178/178 - 3s - loss: 0.0382\n",
            "Epoch 64/100\n",
            "178/178 - 3s - loss: 0.0380\n",
            "Epoch 65/100\n",
            "178/178 - 3s - loss: 0.0365\n",
            "Epoch 66/100\n",
            "178/178 - 3s - loss: 0.0371\n",
            "Epoch 67/100\n",
            "178/178 - 3s - loss: 0.0364\n",
            "Epoch 68/100\n",
            "178/178 - 3s - loss: 0.0360\n",
            "Epoch 69/100\n",
            "178/178 - 3s - loss: 0.0351\n",
            "Epoch 70/100\n",
            "178/178 - 3s - loss: 0.0340\n",
            "Epoch 71/100\n",
            "178/178 - 3s - loss: 0.0335\n",
            "Epoch 72/100\n",
            "178/178 - 3s - loss: 0.0331\n",
            "Epoch 73/100\n",
            "178/178 - 3s - loss: 0.0328\n",
            "Epoch 74/100\n",
            "178/178 - 3s - loss: 0.0322\n",
            "Epoch 75/100\n",
            "178/178 - 3s - loss: 0.0330\n",
            "Epoch 76/100\n",
            "178/178 - 3s - loss: 0.0325\n",
            "Epoch 77/100\n",
            "178/178 - 3s - loss: 0.1504\n",
            "Epoch 78/100\n",
            "178/178 - 3s - loss: 0.0698\n",
            "Epoch 79/100\n",
            "178/178 - 3s - loss: 0.0395\n",
            "Epoch 80/100\n",
            "178/178 - 3s - loss: 0.0341\n",
            "Epoch 81/100\n",
            "178/178 - 3s - loss: 0.0322\n",
            "Epoch 82/100\n",
            "178/178 - 3s - loss: 0.0310\n",
            "Epoch 83/100\n",
            "178/178 - 3s - loss: 0.0311\n",
            "Epoch 84/100\n",
            "178/178 - 3s - loss: 0.0314\n",
            "Epoch 85/100\n",
            "178/178 - 3s - loss: 0.0300\n",
            "Epoch 86/100\n",
            "178/178 - 3s - loss: 0.0314\n",
            "Epoch 87/100\n",
            "178/178 - 3s - loss: 0.0301\n",
            "Epoch 88/100\n",
            "178/178 - 3s - loss: 0.0286\n",
            "Epoch 89/100\n",
            "178/178 - 3s - loss: 0.0293\n",
            "Epoch 90/100\n",
            "178/178 - 3s - loss: 0.0289\n",
            "Epoch 91/100\n",
            "178/178 - 3s - loss: 0.0289\n",
            "Epoch 92/100\n",
            "178/178 - 3s - loss: 0.0292\n",
            "Epoch 93/100\n",
            "178/178 - 3s - loss: 0.0274\n",
            "Epoch 94/100\n",
            "178/178 - 3s - loss: 0.0278\n",
            "Epoch 95/100\n",
            "178/178 - 3s - loss: 0.0273\n",
            "Epoch 96/100\n",
            "178/178 - 3s - loss: 0.0268\n",
            "Epoch 97/100\n",
            "178/178 - 3s - loss: 0.0267\n",
            "Epoch 98/100\n",
            "178/178 - 3s - loss: 0.0281\n",
            "Epoch 99/100\n",
            "178/178 - 3s - loss: 0.0305\n",
            "Epoch 100/100\n",
            "178/178 - 3s - loss: 0.0289\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa67aa8dd10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "mp1CtmA2NsSH"
      },
      "source": [
        "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = model.predict_classes(token_list, verbose=0)\n",
        "        \n",
        "        output_word = \"\"\n",
        "        for word,index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \"+output_word\n",
        "    return seed_text.title()"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4FLg37_NsSI",
        "outputId": "23e4f6f8-78f6-4100-b4a9-0f84f17284d5"
      },
      "source": [
        "print (generate_text(\"I could feel\", 5, model, max_sequence_len))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I Could Feel Dont You Wanna Fall In\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l9wA0XSNsSI",
        "outputId": "650dfa0a-786c-4a90-f380-7c3d71dd0722"
      },
      "source": [
        "print (generate_text(\"Take me\", 4, model, max_sequence_len))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Take Me The Wind Wild Is\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj6iBjtLNsSJ",
        "outputId": "00d7e5f8-de9a-4cf3-8f94-302119b48665"
      },
      "source": [
        "print (generate_text(\"Like The Weather\", 150, model, max_sequence_len))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Like The Weather Fuck About Your Problems Darling When You Can Pay The Rent How Much Is Enough Return To Top Wise The One On Oh The Truth So Tells You Live Im Poor It It You Dont On The Fuck Day On You See Me Get Anymore Nothing Me Or When The Blue Dont Send Me Youre Heaven So Yo Etais Father And You Has Be Lucky To Love Of Found Be Need In No Two Day That Care Care The One Of The Week To All All Youre Will The End Down Ive Youre Down To Give Happiness Can’T Be Alright That I Be No Need To Love Dont So Much Me Hate Go When To Should Come That That You Baby Why Keep Me So Just I Care I Keep Me Baby To Save Me Can I Leave Me You Come Back Care Ourselves Baby Oh The Truth But Here\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}